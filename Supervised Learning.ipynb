{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import dtale\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:/Software/Yandex Practicum/Datasets/churn_beta_bank.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим ненужные столбцы\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Удалим пропущенные значения\n",
    "data = data.dropna()\n",
    "\n",
    "# Конвертируем категориальные переменные в числовые переменные, используя дамми-переменные\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Разделим данные на целевой и обучающие признаки\n",
    "target = data['Exited']\n",
    "features = data.drop('Exited', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление строк с пропущенными значениями (NaN) из набора данных может быть разумным подходом, если процент пропущенных значений относительно невелик и эти пропущенные значения отсутствуют совершенно случайно. В таких случаях удаление строк с пропущенными значениями не окажет существенного влияния на статистические свойства оставшихся данных и, следовательно, на выводы, которые можно сделать из анализа, как в нашем случае! В этом можно убедиться, посмотрев на изначальный необработанный датасет, где единственный столбец Tenure имел всего лишь 909 пропущенных значений из 10.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"475\"\n",
       "            src=\"http://DESKTOP-OJTPT06:40000/dtale/iframe/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x252ba835fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtale.show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        9091 non-null   int64  \n",
      " 1   Age                9091 non-null   int64  \n",
      " 2   Tenure             9091 non-null   float64\n",
      " 3   Balance            9091 non-null   float64\n",
      " 4   NumOfProducts      9091 non-null   int64  \n",
      " 5   HasCrCard          9091 non-null   int64  \n",
      " 6   IsActiveMember     9091 non-null   int64  \n",
      " 7   EstimatedSalary    9091 non-null   float64\n",
      " 8   Exited             9091 non-null   int64  \n",
      " 9   Geography_Germany  9091 non-null   uint8  \n",
      " 10  Geography_Spain    9091 non-null   uint8  \n",
      " 11  Gender_Male        9091 non-null   uint8  \n",
      "dtypes: float64(3), int64(6), uint8(3)\n",
      "memory usage: 736.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исследование задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем баланс классов и потренируем модель логистической регрессии без учета дисбаланса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество положительных экземпляров: 1854\n",
      "\n",
      "Количество отрицательных экземпляров: 7237\n"
     ]
    }
   ],
   "source": [
    "print('Количество положительных экземпляров:', target.sum())\n",
    "print()\n",
    "print('Количество отрицательных экземпляров:', (target == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Набор данных несбалансирован, только 20% положительных экземпляров. Это указывает на то, что положительных примеров (то есть клиентов, которые покинули банк) значительно меньше, чем отрицательных (клиентов, которые остались). Это важно отметить, потому что несбалансированный набор данных может повлиять на производительность некоторых алгоритмов машинного обучения, поскольку они склонны отдавать предпочтение классу большинства.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные на обучающие, валидационные и тестовые выборки.\n",
    "\n",
    "# Разделим данные сначала на обучающие и тестовые выборки со стратификацией, чтобы скорректировать смещение прогноза.\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                                            random_state=12345, stratify=target)\n",
    "\n",
    "# И затем разделим уже обучающий набор на тренировочный и валидационные выборки со стратификацией.\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, test_size=0.25,\n",
    "                                                                              random_state=12345, stratify=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стандартизируем признаки в обоих наборах с помощью StandardScaler(). \n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "features_train = features_train.copy()\n",
    "features_valid = features_valid.copy()\n",
    "features_test = features_test.copy()\n",
    "features_train[numerical_cols] = scaler.fit_transform(features_train[numerical_cols])\n",
    "features_valid[numerical_cols] = scaler.transform(features_valid[numerical_cols])\n",
    "features_test[numerical_cols] = scaler.transform(features_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GasimV\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'max_iter': 10}\n",
      "F1-оценка лог. рег. без учета дисбаланса классов: 0.28\n",
      "Оценка AUC-ROC лог. рег. без учета дисбаланса классов: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Обучим модель логистической регрессии без учета дисбаланса классов и сделаем прогноз.\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for max_iter in range(0, 1000, 10):\n",
    "    model_lr = LogisticRegression(random_state=12345, max_iter=max_iter, solver='liblinear')\n",
    "    model_lr.fit(features_train, target_train)\n",
    "    predicted_valid_lr = model_lr.predict(features_valid)\n",
    "    predicted_prob_lr = model_lr.predict_proba(features_valid)[:, 1]  # predicting the class probabilities for positive class\n",
    "\n",
    "    f1 = f1_score(target_valid, predicted_valid_lr)\n",
    "    auc_roc = roc_auc_score(target_valid, predicted_prob_lr)  # calculating the AUC-ROC using predicted class probabilities\n",
    "\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_params = {'max_iter': max_iter}\n",
    "\n",
    "print('Лучшие гиперпараметры:', best_params)\n",
    "model_lr = LogisticRegression(random_state=12345, solver='liblinear', **best_params)\n",
    "model_lr.fit(features_train, target_train)\n",
    "predicted_valid_lr = model_lr.predict(features_valid)\n",
    "predicted_prob_lr = model_lr.predict_proba(features_valid)[:, 1]  # predicting the class probabilities for positive class\n",
    "print('F1-оценка лог. рег. без учета дисбаланса классов: {:.2f}'.format(f1_score(target_valid, predicted_valid_lr)))\n",
    "print('Оценка AUC-ROC лог. рег. без учета дисбаланса классов: {:.2f}'.format(roc_auc_score(target_valid, predicted_prob_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89      1447\n",
      "           1       0.56      0.19      0.28       371\n",
      "\n",
      "    accuracy                           0.80      1818\n",
      "   macro avg       0.69      0.58      0.58      1818\n",
      "weighted avg       0.77      0.80      0.76      1818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_valid, predicted_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из отчета о классификации видно, что модель хорошо работает в прогнозировании клиентов, которые не собираются уходить, но имеет низкую эффективность в выявлении клиентов, которые собираются уходить. Поэтому может потребоваться улучшить способность модели идентифицировать ушедших клиентов, чтобы делать более точные прогнозы либо использовать другие модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1393,   54],\n",
       "       [ 301,   70]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_valid, predicted_valid_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае матрица ошибок показывает, что модель правильно идентифицировала большое количество отрицательных случаев (клиенты, которые не ушли), но также имеет большое количество ложноотрицательных результатов (клиенты, которые фактически ушли, но, по прогнозам, останутся). Это говорит о том, что модель может не учитывать все важные факторы, влияющие на отток клиентов, и, возможно, ее необходимо улучшить, включив дополнительные признаки, изменив гиперпараметры модели или использовать другую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'n_estimators': 20, 'max_depth': 11}\n",
      "F1-оценка случайного леса без учета дисбаланса классов: 0.59\n",
      "Оценка AUC-ROC случайного леса без учета дисбаланса классов: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Обучим и проверим классификатор случайного леса без учета дисбаланса.\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_estimators in range(10, 101, 10):\n",
    "    for max_depth in range(1, 16):\n",
    "        model_rfc = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=12345)\n",
    "        model_rfc.fit(features_train, target_train)\n",
    "        predicted_valid_rfc = model_rfc.predict(features_valid)\n",
    "        predicted_prob_rfc = model_rfc.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "        f1 = f1_score(target_valid, predicted_valid_rfc)\n",
    "        auc_roc = roc_auc_score(target_valid, predicted_prob_rfc)\n",
    "\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "print('Лучшие гиперпараметры:', best_params)\n",
    "model_rfc = RandomForestClassifier(random_state=12345, **best_params)\n",
    "model_rfc.fit(features_train, target_train)\n",
    "predicted_valid_rfc = model_rfc.predict(features_valid)\n",
    "predicted_prob_rfc = model_rfc.predict_proba(features_valid)[:, 1] \n",
    "print('F1-оценка случайного леса без учета дисбаланса классов: {:.2f}'.format(f1_score(target_valid, predicted_valid_rfc)))\n",
    "print('Оценка AUC-ROC случайного леса без учета дисбаланса классов: {:.2f}'.format(roc_auc_score(target_valid, predicted_prob_rfc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1447\n",
      "           1       0.79      0.47      0.59       371\n",
      "\n",
      "    accuracy                           0.87      1818\n",
      "   macro avg       0.83      0.72      0.75      1818\n",
      "weighted avg       0.86      0.87      0.85      1818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_valid, predicted_valid_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1400,   47],\n",
       "       [ 197,  174]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_valid, predicted_valid_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметен рост показателей, по сравнению с логистической регрессией и целевая метрика достигнута, но необходимо проработать дисбаланс классов при помощи библиотеки imblearn чтобы посмотреть улучшится ли результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Борьба с дисбалансом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшим качество модели с учетом дисбаланса классов. Для этого обучим разные модели и найдем лучшую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'n_estimators': 30, 'max_depth': 15}\n",
      "F1-оценка случайного леса с учетом дисбаланса классов: 0.60\n",
      "Оценка AUC-ROC случайного леса с учетом дисбаланса классов: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Увеличим выборку класса меньшинства, используя SMOTE.\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "smote = SMOTE(random_state=12345)\n",
    "\n",
    "for n_estimators in range(10, 101, 10):\n",
    "    for max_depth in range(1, 16):\n",
    "        model_rfc = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=12345)\n",
    "\n",
    "        features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)\n",
    "        model_rfc.fit(features_train_resampled, target_train_resampled)\n",
    "\n",
    "        predicted_valid_rfc = model_rfc.predict(features_valid)\n",
    "        predicted_valid_rfc_proba = model_rfc.predict_proba(features_valid)[:,1]\n",
    "\n",
    "        f1 = f1_score(target_valid, predicted_valid_rfc)\n",
    "        auc_roc = roc_auc_score(target_valid, predicted_valid_rfc_proba)\n",
    "\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "print('Лучшие гиперпараметры:', best_params)\n",
    "\n",
    "model_rfc_smote = RandomForestClassifier(random_state=12345, **best_params)\n",
    "features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)\n",
    "model_rfc_smote.fit(features_train_resampled, target_train_resampled)\n",
    "\n",
    "predicted_valid_rfc_smote = model_rfc_smote.predict(features_valid)\n",
    "predicted_valid_rfc_smote_proba = model_rfc_smote.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print('F1-оценка случайного леса с учетом дисбаланса классов: {:.2f}'.format(f1_score(target_valid, predicted_valid_rfc_smote)))\n",
    "print('Оценка AUC-ROC случайного леса с учетом дисбаланса классов: {:.2f}'.format(roc_auc_score(target_valid, predicted_valid_rfc_smote_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      1447\n",
      "           1       0.58      0.62      0.60       371\n",
      "\n",
      "    accuracy                           0.83      1818\n",
      "   macro avg       0.74      0.75      0.75      1818\n",
      "weighted avg       0.83      0.83      0.83      1818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_valid, predicted_valid_rfc_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1277,  170],\n",
       "       [ 140,  231]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_valid, predicted_valid_rfc_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Результаты показывают, что использование SMOTE для устранения дисбаланса классов в обучающих данных - улучшило оценку F1 на валидационной выборке по сравнению с предыдущей моделью без SMOTE.\n",
    "\n",
    "- Оценка F1 на валидационной выборке составляет 0.60, что лучше, чем оценка F1 предыдущей модели, равная 0.59, что указывает на то, что метод SMOTE улучшил способность модели предсказывать класс меньшинства.\n",
    "\n",
    "- Оценка AUC-ROC составляет 0.85, что является относительно высоким показателем, указывающим на то, что модель обладает хорошей способностью различать положительные и отрицательные классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Окончательные результаты тестирования классификатора случайного леса с увеличением выборки с помощью метода SMOTE.\n",
      "F1: 0.59\n",
      "AUC-ROC: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Оценим производительность моделей на тестовых данных\n",
    "predictions_test = model_rfc_smote.predict(features_test)\n",
    "predicted_test_rfc_smote_proba = model_rfc_smote.predict_proba(features_test)[:,1]\n",
    "\n",
    "f1 = f1_score(target_test, predictions_test)\n",
    "auc_roc = roc_auc_score(target_test, predicted_test_rfc_smote_proba)\n",
    "print(\"Окончательные результаты тестирования классификатора случайного леса с увеличением выборки с помощью метода SMOTE.\")\n",
    "print(\"F1: {:.2f}\".format(f1))\n",
    "print(\"AUC-ROC: {:.2f}\".format(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "   1. Судя по результатам, классификатор случайного леса с увеличением числа примеров миноритарного класса при помощи метода SMOTE превзошел две другие модели. Показатель F1 достиг целевого показателя (0.59) на тестовой выборке, а показатель AUC-ROC составил 0.84. Эти улучшения предполагают, что метод SMOTE успешно сбалансировал данные и улучшил общую производительность модели.  \n",
    "\n",
    "\n",
    "   2. При сравнении двух моделей, в которых не учитывался дисбаланс, классификатор случайного леса работал лучше, чем модель логистической регрессии, с точки зрения обоих метрик (F1 и AUC-ROC). Это говорит о том, что модель случайного леса может лучше подходить для этого конкретного набора данных.  \n",
    "\n",
    "В целом - основной вывод такой, что при построении моделей машинного обучения важно учитывать дисбаланс классов. SMOTE является эффективным методом, используемым для устранения дисбаланса классов, и полученные здесь результаты показывают, что он может быть эффективным также для улучшения производительности модели. Однако важно отметить, что результаты могут различаться в зависимости от конкретного набора данных и используемой модели, и может потребоваться попробовать несколько методов, чтобы найти наилучший подход для конкретной проблемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
